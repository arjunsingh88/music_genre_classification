{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Genre Classification\n",
    "# About the dataset:\n",
    "The GTZAN genre collection dataset was collected in 2000-2001. It consists of 1000 audio files each having 30 seconds duration. There are 10 classes ( 10 music genres) each containing 100 audio tracks. Each track is in .wav format. It contains audio files of the following 10 genres:\n",
    "\n",
    "* Blues\n",
    "* Classical\n",
    "* Country\n",
    "* Disco\n",
    "* Hiphop\n",
    "* Jazz\n",
    "* Metal\n",
    "* Pop\n",
    "* Reggae\n",
    "* Rock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Genre Classification approach:\n",
    "\n",
    "There are various methods to perform classification on this dataset. Some of these approaches are:\n",
    "\n",
    "* Multiclass support vector machines\n",
    "* K-means clustering\n",
    "* K-nearest neighbors\n",
    "* Convolutional neural networks\n",
    "We will use K-nearest neighbors algorithm because in various researches it has shown the best results for this problem.\n",
    "\n",
    "# Algorithm \n",
    "K-Nearest Neighbors is a popular machine learning algorithm for regression and classification. It makes predictions on data points based on their similarity measures i.e distance between them.\n",
    "\n",
    "# Feature Extraction:\n",
    "The first step for music genre classification project would be to extract features and components from the audio files. It includes identifying the linguistic content and discarding noise.\n",
    "\n",
    "Note: \n",
    "Mel Frequency Cepstral Coefficients:\n",
    "These are state-of-the-art features used in automatic speech and speech recognition studies. There are a set of steps for generation of these features:\n",
    "\n",
    "* Since the audio signals are constantly changing, first we divide these signals into smaller frames. Each frame is around 20-40 ms long\n",
    "* Then we try to identify different frequencies present in each frame\n",
    "* Now, separate linguistic frequencies from the noise\n",
    "* To discard the noise, it then takes discrete cosine transform (DCT) of these frequencies. Using DCT we keep only a specific sequence of frequencies that have a high probability of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_speech_features import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "from tempfile import TemporaryFile\n",
    "import os\n",
    "import pickle\n",
    "import random \n",
    "import operator\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define a function to get the distance between feature vectors and find neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(instance1 , instance2 , k ):\n",
    "    distance =0 \n",
    "    mm1 = instance1[0] \n",
    "    cm1 = instance1[1]\n",
    "    mm2 = instance2[0]\n",
    "    cm2 = instance2[1]\n",
    "    distance = np.trace(np.dot(np.linalg.inv(cm2), cm1)) \n",
    "    distance+=(np.dot(np.dot((mm2-mm1).transpose() , np.linalg.inv(cm2)) , mm2-mm1 )) \n",
    "    distance+= np.log(np.linalg.det(cm2)) - np.log(np.linalg.det(cm1))\n",
    "    distance-= k\n",
    "    return distance\n",
    "\n",
    "def getNeighbors(trainingSet, instance, k):\n",
    "    distances = []\n",
    "    for x in range (len(trainingSet)):\n",
    "        dist = distance(trainingSet[x], instance, k )+ distance(instance, trainingSet[x], k)\n",
    "        distances.append((trainingSet[x][2], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identify the nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearestClass(neighbors):\n",
    "    classVote = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x]\n",
    "        if response in classVote:\n",
    "            classVote[response]+=1 \n",
    "        else:\n",
    "            classVote[response]=1\n",
    "    sorter = sorted(classVote.items(), key = operator.itemgetter(1), reverse=True)\n",
    "    return sorter[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define a function for model evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0 \n",
    "    for x in range (len(testSet)):\n",
    "        if testSet[x][-1]==predictions[x]:\n",
    "            correct+=1\n",
    "    return 1.0*correct/len(testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract features from the dataset and dump these features into a binary .dat file “my.dat”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data/genres/\"\n",
    "f= open(\"my.dat\" ,'wb')\n",
    "i=0\n",
    "for folder in os.listdir(directory):\n",
    "    if not folder.__contains__('.'):\n",
    "        i+=1\n",
    "        if i==11 :\n",
    "            break   \n",
    "        for file in os.listdir(directory+folder):\n",
    "            #print(os.listdir(directory+folder))\n",
    "            if not file.startswith('.'):\n",
    "                rate,sig = wav.read(directory+folder+\"/\"+file)\n",
    "                mfcc_feat = mfcc(sig,rate ,winlen=0.020, appendEnergy = False)\n",
    "                covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "                mean_matrix = mfcc_feat.mean(0)\n",
    "                feature = (mean_matrix , covariance , i)\n",
    "                pickle.dump(feature , f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train and test split on the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "def loadDataset(filename , split , trSet , teSet):\n",
    "    with open(\"my.dat\" , 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                dataset.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                f.close()\n",
    "                break  \n",
    "    for x in range(len(dataset)):\n",
    "        if random.random() <split :      \n",
    "            trSet.append(dataset[x])\n",
    "        else:\n",
    "            teSet.append(dataset[x])  \n",
    "trainingSet = []\n",
    "testSet = []\n",
    "loadDataset(\"my.dat\" , 0.66, trainingSet, testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Make prediction using KNN and get the accuracy on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6735905044510386\n"
     ]
    }
   ],
   "source": [
    "leng = len(testSet)\n",
    "predictions = []\n",
    "for x in range (leng):\n",
    "    predictions.append(nearestClass(getNeighbors(trainingSet ,testSet[x] , 5))) \n",
    "accuracy1 = getAccuracy(testSet , predictions)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "results = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {1: 'pop', 2: 'metal', 3: 'disco', 4: 'blues', 5: 'reggae', 6: 'classical', 7: 'rock', 8: 'hiphop', 9: 'country', 10: 'jazz'})\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for folder in os.listdir(\"data/genres/\"):\n",
    "    if not folder.__contains__('.'):\n",
    "        results[i] = folder\n",
    "        i+=1\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate,sig = wav.read(directory+folder+\"/\"+file)\n",
    "mfcc_feat = mfcc(sig,rate ,winlen=0.020, appendEnergy = False)\n",
    "covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "mean_matrix = mfcc_feat.mean(0)\n",
    "feature = (mean_matrix , covariance , i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = nearestClass(getNeighbors(trainingSet ,testSet[x] , 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[pred])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
